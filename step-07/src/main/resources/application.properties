quarkus.langchain4j.openai.chat-model.model-name=meta-llama-31-8b-instruct
quarkus.langchain4j.openai.base-url=${LLAMA_URL}
quarkus.langchain4j.openai.timeout=60s

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true
quarkus.langchain4j.openai.chat-model.temperature=0.1
#quarkus.langchain4j.openai.chat-model.max-tokens=1000
#quarkus.langchain4j.openai.chat-model.frequency-penalty=0
quarkus.langchain4j.pgvector.dimension=384
rag.location=src/main/resources/rag
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel
