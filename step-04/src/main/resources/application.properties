quarkus.langchain4j.openai.chat-model.model-name=meta-llama-31-8b-instruct
quarkus.langchain4j.openai.base-url=${LLAMA_URL}
quarkus.langchain4j.openai.timeout=60s

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true

quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0
