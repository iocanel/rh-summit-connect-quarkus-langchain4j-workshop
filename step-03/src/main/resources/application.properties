quarkus.langchain4j.openai.chat-model.model-name=mistral7b03-vllm-gpu
quarkus.langchain4j.openai.base-url=${MISTRAL_URL}
quarkus.langchain4j.openai.timeout=60s

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true

quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0
