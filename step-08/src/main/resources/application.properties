
quarkus.langchain4j.openai.chat-model.model-name=mistral7b03-vllm-gpu
quarkus.langchain4j.openai.base-url=${MISTRAL_URL}
quarkus.langchain4j.openai.timeout=60s

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true
quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0
quarkus.langchain4j.pgvector.dimension=384
rag.location=src/main/resources/rag
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel
